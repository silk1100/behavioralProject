{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import json\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_dir = '../models/20210816_230313_perc_ubuntu_cog/'\n",
    "main_dir = '../models/20211101_190014'\n",
    "output_dir = f'{main_dir}/ML_obj_hyperparams'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(main_dir, 'ML_obj.p'), 'rb') as f:\n",
    "    ml_obj = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'param_distributions': {'hidden_layer_sizes': [(200,),\n",
       "   (150,),\n",
       "   100,\n",
       "   (150, 100, 50),\n",
       "   (100, 50, 25)],\n",
       "  'activation': ['relu'],\n",
       "  'solver': ['adam'],\n",
       "  'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5],\n",
       "  'learning_rate': ['constant', 'adaptive'],\n",
       "  'beta_1': [0, 0.001, 0.01, 0.1, 0.3, 0.5, 0.9],\n",
       "  'beta_2': [0, 0.001, 0.01, 0.1, 0.3, 0.5, 0.9]},\n",
       " 'n_iter': 1,\n",
       " 'random_state': None,\n",
       " 'scoring': 'balanced_accuracy',\n",
       " 'estimator': MLPClassifier(max_iter=1000000000),\n",
       " 'n_jobs': -1,\n",
       " 'iid': 'deprecated',\n",
       " 'refit': True,\n",
       " 'cv': 5,\n",
       " 'verbose': 3,\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'error_score': nan,\n",
       " 'return_train_score': False,\n",
       " 'multimetric_': False,\n",
       " 'best_index_': 0,\n",
       " 'best_score_': 0.7942800944829342,\n",
       " 'best_params_': {'solver': 'adam',\n",
       "  'learning_rate': 'adaptive',\n",
       "  'hidden_layer_sizes': (150,),\n",
       "  'beta_2': 0.9,\n",
       "  'beta_1': 0.9,\n",
       "  'alpha': 0.05,\n",
       "  'activation': 'relu'},\n",
       " 'best_estimator_': MLPClassifier(alpha=0.05, beta_2=0.9, hidden_layer_sizes=(150,),\n",
       "               learning_rate='adaptive', max_iter=1000000000),\n",
       " 'refit_time_': 0.6992461681365967,\n",
       " 'scorer_': make_scorer(balanced_accuracy_score),\n",
       " 'cv_results_': {'mean_fit_time': array([0.56694331]),\n",
       "  'std_fit_time': array([0.02304483]),\n",
       "  'mean_score_time': array([0.00039997]),\n",
       "  'std_score_time': array([0.00048986]),\n",
       "  'param_solver': masked_array(data=['adam'],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_learning_rate': masked_array(data=['adaptive'],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_hidden_layer_sizes': masked_array(data=[(150,)],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_beta_2': masked_array(data=[0.9],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_beta_1': masked_array(data=[0.9],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_alpha': masked_array(data=[0.05],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_activation': masked_array(data=['relu'],\n",
       "               mask=[False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'solver': 'adam',\n",
       "    'learning_rate': 'adaptive',\n",
       "    'hidden_layer_sizes': (150,),\n",
       "    'beta_2': 0.9,\n",
       "    'beta_1': 0.9,\n",
       "    'alpha': 0.05,\n",
       "    'activation': 'relu'}],\n",
       "  'split0_test_score': array([0.8876698]),\n",
       "  'split1_test_score': array([0.77951933]),\n",
       "  'split2_test_score': array([0.76907001]),\n",
       "  'split3_test_score': array([0.78676471]),\n",
       "  'split4_test_score': array([0.74837662]),\n",
       "  'mean_test_score': array([0.79428009]),\n",
       "  'std_test_score': array([0.04845343]),\n",
       "  'rank_test_score': array([1])},\n",
       " 'n_splits_': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_obj['lr']['nn'].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_cv_results(cv_results_dict, cv):\n",
    "    interesting_keys = [\n",
    "        'mean_test_score',\n",
    "        'std_test_score'\n",
    "    ]\n",
    "    split_keys = [f'split{i}_test_score' for i in range(cv)]\n",
    "    intersting_dict = {}\n",
    "    for key in interesting_keys:\n",
    "        intersting_dict[key] = cv_results_dict[key]\n",
    "    for key in split_keys:\n",
    "        intersting_dict[key] = cv_results_dict[key]\n",
    "    return intersting_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 'loss_')\n"
     ]
    }
   ],
   "source": [
    "for rfe_key in ml_obj:\n",
    "    ml_dict = ml_obj[rfe_key]\n",
    "    for clc_name, clc in ml_dict.items():\n",
    "        hyper_dict = clc.best_estimator_.__dict__\n",
    "        modified_dict = {}\n",
    "        best_params = clc.best_params_\n",
    "        best_idx = clc.best_index_\n",
    "        best_score = clc.best_score_\n",
    "        cv_results = clc.cv_results_\n",
    "        cv_results = mine_cv_results(cv_results, clc.cv)\n",
    "        tobedelted = (False,None)\n",
    "        for key, val in hyper_dict.items():\n",
    "            if key in ['_Booster', '_le', 'base_estimator_','estimators_','base_estimator',\n",
    "                       '_tree','_y','_fit_X','loss_','init_','_rng']:\n",
    "                tobedeleted= (True, key)\n",
    "                print(tobedeleted)\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                modified_dict[key] = val.tolist()\n",
    "            elif isinstance(val, np.int32):\n",
    "                modified_dict[key] = int(val)\n",
    "            elif isinstance(val, np.int64):\n",
    "                modified_dict[key] = int(val)\n",
    "            elif key in ['_label_binarizer', '_random_state','_optimizer']:\n",
    "                modified_dict[key] = str(val)\n",
    "            \n",
    "            elif (key == 'coefs_') or (key == 'intercepts_'):\n",
    "                updated_v = []\n",
    "                for v in val:\n",
    "                    updated_v.append(v.tolist())\n",
    "                modified_dict[key] = updated_v\n",
    "\n",
    "            else:\n",
    "                modified_dict[key] = val\n",
    "        \n",
    "\n",
    "        for key, val in cv_results.items():\n",
    "            if key in ['_Booster', '_le', 'base_estimator_','estimators_','base_estimator',\n",
    "                       '_tree','_y','_fit_X','loss_','init_','_rng']:\n",
    "                tobedeleted= (True, key)\n",
    "                print(tobedeleted)\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                modified_dict[key] = val.tolist()\n",
    "            elif isinstance(val, np.int32):\n",
    "                modified_dict[key] = int(val)\n",
    "            elif isinstance(val, np.int64):\n",
    "                modified_dict[key] = int(val)\n",
    "            elif key in ['_label_binarizer', '_random_state','_optimizer']:\n",
    "                modified_dict[key] = str(val)\n",
    "            \n",
    "            elif (key == 'coefs_') or (key == 'intercepts_'):\n",
    "                updated_v = []\n",
    "                for v in val:\n",
    "                    updated_v.append(v.tolist())\n",
    "                modified_dict[key] = updated_v\n",
    "\n",
    "            else:\n",
    "                modified_dict[key] = val\n",
    "        params_dict = {}\n",
    "        for key, val in best_params.items():\n",
    "            if key in ['_Booster', '_le', 'base_estimator_','estimators_','base_estimator',\n",
    "                       '_tree','_y','_fit_X','loss_','init_','_rng']:\n",
    "                tobedeleted= (True, key)\n",
    "                print(tobedeleted)\n",
    "            elif isinstance(val, np.ndarray):\n",
    "                params_dict[key] = val.tolist()\n",
    "            elif isinstance(val, np.int32):\n",
    "                params_dict[key] = int(val)\n",
    "            elif isinstance(val, np.int64):\n",
    "                params_dict[key] = int(val)\n",
    "            elif key in ['_label_binarizer', '_random_state','_optimizer']:\n",
    "                params_dict[key] = str(val)\n",
    "            \n",
    "            elif (key == 'coefs_') or (key == 'intercepts_'):\n",
    "                updated_v = []\n",
    "                for v in val:\n",
    "                    updated_v.append(v.tolist())\n",
    "                params_dict[key] = updated_v\n",
    "\n",
    "            else:\n",
    "                params_dict[key] = val\n",
    "        \n",
    "        modified_dict['best_params'] = params_dict\n",
    "\n",
    "        if tobedelted[0]:\n",
    "            del hyper_dict[tobedeleted[1]]\n",
    "        \n",
    "        with open(os.path.join(output_dir, f'{rfe_key}_{clc_name}.json'), 'w') as f:\n",
    "            try:\n",
    "                json.dump(modified_dict, f)\n",
    "            except Exception:\n",
    "                print(modified_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sklearn.neural_network._stochastic_optimizers.AdamOptimizer object at 0x0000023BE2586A88>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(modified_dict['_optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'adam',\n",
       " 'learning_rate': 'adaptive',\n",
       " 'hidden_layer_sizes': (150,),\n",
       " 'beta_2': 0.9,\n",
       " 'beta_1': 0.9,\n",
       " 'alpha': 0.05,\n",
       " 'activation': 'relu'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "169a73084fb5035b042011a12ba7add2514f1ab95c1535ba5df082a9592678f6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('brain_torch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
